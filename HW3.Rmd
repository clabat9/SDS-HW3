---
title: "Statistical Methods in Data Science"
subtitle : "Homework 3" 
author: "Claudio Battiloro, Egon Ferri"
output:
  prettydoc::html_pretty:
    theme: hpstr
    highlight: github
    self_contained: yes
    toc: true
    toc_depth: 4
    number_sections: true
    df.print: tibble
    css: css_custom.css
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
    

---
<style>
a:link {
    color: darkred;
}
a:visited{
    color: darkred;
}
a:hover {
    color: orange;
}


</style>

\usepackage{asmath}



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(Rfast)
library(knitr)
require(R2jags)
library(latex2exp)
library(MASS)
library(ggplot2)
```


<img src = "https://www.sciencenews.org/sites/default/files/2016/05/main/articles/052816_bayesian-opener_free.jpg" />



# Graphical Models


    
A graphical model or probabilistic graphical model (PGM) or structured probabilistic model is a probabilistic model for which a graph expresses the conditional dependence structure between random variables. They are commonly used in probability theory, statistics-particularly Bayesian statistics-and machine learning.

Graphs can be oriented -edges encode an orientation- or not.
Graphs with attached a probabilistic semantic come in different flavors, such as:

- Marginal Correlation Graphs.

- Partial Correlation Graphs.

- Conditional Independence Graphs.

## Conditional Independence graphs: an introduction

Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a distribution over a multi-dimensional space and a graph that is a compact or factorized representation of a set of independences that hold in the specific distribution. Two branches of graphical representations of distributions are commonly used, namely, Bayesian networks and Markov random fields. Both families encompass the properties of factorization and independences, but they differ in the set of independences they can encode and the factorization of the distribution that they induce.

In this work we focus our attention on **Bayesian Networks**.

## Bayesian Networks

Bayesian networks are a type of probabilistic graphical model that uses Bayesian inference for probability computations. Bayesian networks aim to model conditional dependence, and therefore causation, by representing conditional dependence by edges in a directed graph. Through these relationships, one can efficiently conduct inference on the random variables in the graph through the use of factors.

Using the relationships specified by our Bayesian network, we can obtain a compact, factorized representation of the joint probability distribution by taking advantage of conditional independence.

A Bayesian network is a **directed acyclic** graph (DAG) in which each edge corresponds to a conditional dependency, and each node corresponds to a unique random variable. Formally, if an edge $(A, B)$ exists in the graph connecting random variables A and B, it means that $P(B|A)$ is a factor in the joint probability distribution, so we must know $P(B|A)$ for all values of $B$ and $A$ in order to conduct inference.

The fundamental property of BNs is the **Local Markov Condition**, which states that a node is conditionally independent of its non-descendants given its parents.

Formally:

*Given a directed graph $G = (V,E)$ with vertices $V = \{ X_1, . . . ,X_D \}$ where $|V| = D$, we define the local Markov property or just Markov property to be the assumption that:*

\[ (X_d \perp \mathbf{X}_{ \{ndes(d) - pa(d)\} }|\mathbf{X}_{pa(d)}) \]

*where $pa(d)$ are the parents of node $d$, and $ndes(d)$ are the non-descendants of node d.*


Another important property holds if the nodes are ordered such that parent-nodes come before their children-nodes.

*The vertices $V$ of a DAG $G$ are well-ordered if they are linearly ordered in a way which is compatible with $D$, so that:*

\[ v \in pa(d) \implies v < d \]

This is called a topological ordering and it can be built for any DAG. With such an order, we can give the following **Ordered Markov Condition**:

*Given a directed graph $G = (V,E)$ with vertices $V = \{ X_1, . . . ,X_D \}$ where $|V| = D$, we define the ordered Markov property or just Markov property to be the assumption that:*

\[ (X_d \perp \mathbf{X}_{ \{pred(d) - pa(d)\} }|\mathbf{X}_{pa(d)}) \]

*where $pa(d)$ are the parents of node $d$, and $pred(d)$ are the predecessor of node d.*

Both this properties imply that the joint distribution defined over such a DAG admits the following **factorization**:

\[  p(X_{1:D} | G) = \prod_{d = 1}^D p(X_d|\mathbf{X}_{pa(d)}) \, \, \text{[1]}\]

Observe that this properties are satisfied by a distribution relative to a specific DAG. This means that being Markov is a property of the distribution, not the graph (although it is only defined relative to a given graph). A graph can't be Markov or fail to be Markov, but a distribution can fail to be Markov relative to a given graph.

Reasoning in terms of causality, Markov condition is only reasonable when the graph includes all common causes of any pair of nodes in the graph (an assumption called "causal sufficiency"). 

### d-separation

There are many ways to carry out the conditional independeces induced by a Bayesian Network. The main one is clearly applying the Markov property but there is another more formal procedure called **d-separation**.

This concept is translated in statistical terms by classical graph theory and states that:

*Given a general directed graph $G = (V, E)$ in which $\mathbf{X}_A$, $\mathbf{X}_B$ and $\mathbf{X}_C$ are three arbitrary disjoint sets of nodes. Consider all possible undirected paths $U$ from any node in $\mathbf{X}_A$ to any node in $\mathbf{X}_B$.*

*Any such path is said to be **blocked** if and only if at least one of the following conditions hold:*

*- $U$ contains a chain whose node $\in \mathbf{X}_C$.*

*- $U$ contains a tent or common cause whose node $\in \mathbf{X}_C$.* 

*- $U$ contains a collider whose node $\in \mathbf{X}_C$ and nor is any of its descendants.*

*If all paths are **blocked**, then $\mathbf{X}_A$ is said to be d-separated from $\mathbf{X}_B$ by $\mathbf{X}_C$, and the joint distributions over all the variables in the graph will satisfy $(\mathbf{X}_A \perp \mathbf{X}_{ B}|\mathbf{X}_{C})$.*

In this statement we used some terms that are related to particular classical types of subgraphs. A visualization of the definition:

<img src="https://i.imgur.com/dkcJEXG.png" />


# Applications 

##Exercise I: Ultra-fast exercise


Look at the two DAGs below and use **d-separation + Markov condition** to check whether the indicated conditional independence relationships are satisfied.

<img src="https://i.imgur.com/FTOuhNd.png"/>

From **Local Markov Condition** we find this CIs:

  - $(X_2 \perp \{ X_3,X_5 \}|X_1)$

  - $(X_3 \perp \{ X_2,X_4 \}|X_1)$

  - $(X_4 \perp \{ X_1,X_3,X_5,X_6 \}|X_2)$

  - $(X_5 \perp \{ X_1,X_2,X_4 \}|X_3)$

  - $(X_6 \perp \{ X_1,X_3,X_4 \}|X_2, X_5)$

 


No one of these answers the questions (maybe not explicitily, let's say), so we cann apply **d-separation** procedure to verify it.

-- Let's focus on number *(1)*.

There are two possible *undirected* paths from  $X_2$ to $X_3$:

  1. $U_1 := \{ X_2, X_1, X_3 \}$ .


<img src="https://i.imgur.com/j0Sus02.jpg"/>

This first one is **blocked** becouse $X_1 \in \{X_1, X_6\}$ is the center of a tent.

  2. $U_2 := \{ X_2, X_6, X_5, X_3 \}$ .
  
<img src="https://i.imgur.com/O48bVj6.jpg"/>


This second one is **not blocked** becouse $X_6 \in \{X_1, X_6\}$ is the center of a collider.

So the statement $(X_2 \perp  X_3|\{X_1,X_6\})$ is **false**.

-- Let's focus on number *(2)* . 

There are two possible *undirected* paths from  $X_1$ to $X_6$:

  1. $W_1 := \{ X_1, X_2, X_6 \}$ .
  
  2. $W_2 := \{ X_1, X_3, X_5, X_6 \}$ .
  
<img src="https://i.imgur.com/A7j6AOK.jpg"/>

Both of them are **blocked** becouse $X_2$ and $X_3 \in \{X_2,X_3\}$ and they are the center of [two chains](https://en.wikipedia.org/wiki/2_Chainz).
  
So the statement $(X_1 \perp  X_6|\{X_2,X_3 \})$ is **true**.


We can directly check this result by showing if $p(X_6|\mathbf{X}_{1:3}) = p(X_6|\mathbf{X}_{2:3})$ or not (we know that this is one of the definitions of Conditional Independence). This can be done by explicitly writing the two statements using the factorization rule in $[1]$:

$$p(X_6|\mathbf{X}_{1:3}) = p(X_6|X_2)$$
$$p(X_6|\mathbf{X}_{2:3}) = p(X_6|X_2)$$

And so : 

$$p(X_6|\mathbf{X}_{1:3}) = p(X_6|\mathbf{X}_{2:3})$$

##Exercise II: Sampling a DAG

Consider the following (Bayesian) model in DAG format:

<img src="https://i.imgur.com/RkDxqgI.png"/>

where, conditionally on $\boldsymbol{\mu}=[\mu_1, \mu_2]^T$ and $\sigma^2$, we assume that:

- $\mathbf{X} = [X_1, X_2]^T \stackrel{}{\sim} N_2(\boldsymbol{\mu},\sigma^2 \mathbb{I}_2 ) \,\,\, [2.1]$

- $\mathbf{Y} = [Y_1, Y_2]^T \stackrel{}{\sim} N_2(\boldsymbol{\mu},\sigma^2 \mathbb{I}_2 ) \,\,\, [2.2]$


Using again tha factorization rule $[1]$ we can write down the joint distribution corresponding to this DAG:

$$ p(\mathbf{X},\mathbf{Y},\boldsymbol{\mu}, \sigma^2) = p(\boldsymbol{\mu})p(\sigma^2)p(X_1|\boldsymbol{\mu},\sigma^2)p(Y_2|\boldsymbol{\mu},\sigma^2)p(X_2|X_1,\boldsymbol{\mu},\sigma^2)p(Y_1|Y_2,\boldsymbol{\mu},\sigma^2) \,\,\,\, [3] $$
Before focusing on priors for $\boldsymbol{\mu}$ and $\sigma^2$, we can make some important observations about the other factors in the previous formula deriving from the theory about Multivariate Normal Distribution. 

Assuming that basic concepts about Normal distribution and covariance matrix are clear, we know that:

$$ \mathbf{W} = [W_1,..,W_D]^T \stackrel{}{\sim}N_D(\boldsymbol{\mu},\Sigma) \implies (\mathbf{W}_1|\mathbf{W}_2 = \mathbf{w}_2)\stackrel{}{\sim} N(\boldsymbol{\mu}_{1|2}, \Sigma_{1|2}) $$

Where:

- $\mathbf{W}_1 \in \mathbb{R}^q$ and $\mathbf{W}_1 \in \mathbb{R}^{D-q}$ represent a partition of $\mathbf{W} \in \mathbb{R}^D$

- $\boldsymbol{\mu}_{1|2} = \boldsymbol{\mu}_1 + \Sigma_{12}\Sigma_{2|2}^{-1}(\mathbf{w}_2 - \boldsymbol{\mu}_2 )$

- $\Sigma_{1|2} = \Lambda_{11}^{-1} = \Sigma_{11} - \Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}$ is called **Schur complement**.

Moreover, it can be shown that the marginal distros are:

- $\mathbf{W}_1 \stackrel{}{\sim} N(\boldsymbol{\mu}_1, \Sigma_{11})$ 

- $\mathbf{W}_2 \stackrel{}{\sim} N(\boldsymbol{\mu}_2, \Sigma_{22})$ 

Last but not least, if some RVs are jointly Multivariate Normal and they're not correlated  (it means that the non-diagonal elements of the block matrix $\Sigma$ are $\mathbf{0}$), they're **independent** too.

Based on this properties, the equation in $[2]$ can be better defined observing that:

- $(X_1|\boldsymbol{\mu},\sigma^2)\stackrel{}{\sim}N(\mu_1,\sigma^2)$

- $(Y_2|\boldsymbol{\mu},\sigma^2) \stackrel{}{\sim}N(\mu_2,\sigma^2)$

- $(X_2|X_1,\boldsymbol{\mu},\sigma^2) \stackrel{}{\sim} N(\mu_2, \sigma^2)$ due to the fact that from $[2.1]$ we can state $(X_2 \perp X_1 | \boldsymbol{\mu},\sigma^2)$

- $(Y_1|Y_2,\boldsymbol{\mu},\sigma^2) \stackrel{}{\sim} N(\mu_1, \sigma^2)$ due to the fact that from $[2.2]$ we can state $(Y_1 \perp Y_2 | \boldsymbol{\mu},\sigma^2)$

### Ancestral Sampling

We're interested in sampling from the joint distro of this DAG and then estimate the **prior predictive distribution** of $\mathbf{X}$. In order to do this we use a method  called **ancestral (or forward) sampling**. Given a probability $p(\mathbf{X})$ specified by a Bayes network, we sample variables in topological order. In other words, we start by sampling the variables with no parents; then we sample from the next generation by conditioning these variables' CPDs to values sampled at the first step. We proceed like this until the all variables have been sampled.

It's fundamental, at this point, the choice of priors for $\mu$ and $\sigma$. This is a pretty tricky point and depends on our belief. Theoretically there are various ways to deal with [Normal Likelihood using conjugated priors](https://www.statlect.com/fundamentals-of-statistics/normal-distribution-Bayesian-estimation) but all of these require conditions that, given this BN, cannot be respected. In particular both mean and variance are unknown and, in this case, the only way to reach conjugation is the following hierarchical model know as **Normal Likelihood - NormalGammaInverse Prior**:

$$X_i \stackrel{}{\sim} N(\mu,\sigma)$$
$$\mu|\sigma^2 \stackrel{}{\sim} N(\mu_0,\sigma^2)$$
$$\sigma^2 \stackrel{}{\sim} Ga^{-1}(\alpha,\beta)$$
It can be shown that, using this model, the predictive prior follows a **multivariate student-t** distribution and so each draw $X_i$ follows a **student-t distribution**.

The problem is that our graphical model induces marginal independence between $\mu$ and $\sigma^2$
(despite they're conditional dependent on $\mathbf{X}$ and $\mathbf{Y}$) so we cannot use the upper priors.

Unable to get a closed form for the prior predictive distribution, we decided to choose two non informative priors, assume marginal independence between the components of $\boldsymbol{\mu}$ and then make some tests to check which theoretical distribution are we approacching to.

In particular, we've choosen:

- $\mu_1,\mu_2 \stackrel{}{\sim} N(\mu_0,sigma^2_0)$ with:

  -- $\mu_0 = 0$
  
  -- $\sigma^2_0 = 20$
  
Non-informative: zero mean and high variance.

```{r echo=FALSE}
curve(dnorm(x,0,20), ylab = TeX("$\\mu_i$"), from = -100, to = 100, col = "orange", lwd='3')
```


- $\sigma^2 \stackrel{}{\sim}G(\alpha,\beta)$ with:

  -- $\alpha = 0.01$
  
  -- $\sigma^2_0 = 0.01$
  
[Non informative](https://math.stackexchange.com/questions/449234/vague-gamma-prior):  this distribution $\Gamma(\alpha=0.001,\beta=0.001)$ has most of its mass very close to 0, but it also has an impressive tail, so in fact its mean is 1.It is non informative in the sense that as soon as we update it based on our empirical observation, the posterior distribution will tell us that whatever data point we observed is a very typical one. Put another way, it reflects a belief that is very weakly held and easily molded by exposure to new information.
  
  
```{r echo=FALSE}
curve(dgamma(x,0.01,0.01), ylab = TeX("$\\sigma^2$"), from = 0, to = 50, col = "orange", lwd='3')
```
  

It's time to perform the sampling following the aforementioned forwarding rule.

```{r}

# This function implments the ancestral sampling. Not too much to comment, simple code.
ancestral_sampling <- function(x){
sigma2 <- rgamma(1,.01,.01)
mu <- c(rnorm(n = 1,0,sqrt(20)), rnorm(n = 1,0,sqrt(20)))
xx1 <- rnorm( n = 1, mean = mu[1], sd = sqrt(sigma2))
xx2 <- rnorm(n = 1,mean = mu[2], sd = sqrt(sigma2))
yy1 <- rnorm( n = 1, mean = mu[1], sd = sqrt(sigma2))
yy2 <- rnorm(n = 1,mean = mu[2], sd = sqrt(sigma2)) 
return (c(var = sigma2, mean1 = mu[1], mean2 = mu[2], x1 = xx1, x2 = xx2, y1 = yy1, y2 = yy2))
}

M = 200000 # Sample size
sample_ <- sapply(1:M, ancestral_sampling) # Vectorized procedure
```

Got our sample of the joint distribution we can check what's happening at the marginal distributions of $\mathbf{X}$:

```{r echo=FALSE}
X1=sample_[4,]
hist(X1, prob = T,breaks = 100, col = "orange", border = "white",xlab = TeX("$X_1$"), main = TeX("$X_1\\,\\,\\,Distribution"))

```




```{r echo=FALSE}
hist(sample_[5,], prob = T,breaks = 100, col = "orange", border = "white",xlab = TeX("$X_2$"), main = TeX("$X_2\\,\\,\\,Distribution"))

```

These distributions seems to be pretty normal. We can check it by making a [Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test). There are various kind of this test, we're interested in the **one sample Kolmogorov-Smirnov** test for testing if a variable follows a given distribution in a population. This "given distribution" is usually -and in our case- the normal distribution, hence "Kolmogorov-Smirnov normality test".

In a KS test, the null hypothesis is that our sample follows the distribution we compare it against. So higher is the statistic, higher is valid the rejection of the null. In fact, without going too much deep, we can consider the statistics as a measure of the distance (in particular the $\operatorname{sup}$) between the empirical distributions of the sample and the distribution we think it follows. So we cannot reject the null for low values of the statistics.

Let's run the test comparing the empirical distibution of $X_1$ against the following $N(\bar{X}_1, S_n^2(X_1))$:

```{r echo=FALSE}
X1=sample_[4,]
hist(X1, prob = T,breaks = 100, col = "orange", border = "white",xlab = TeX("$X_1$"), main = TeX("$X_1\\,\\,\\,Distribution"))
curve(dnorm(x  ,mean = mean(sample_[4,]), sd = sd(sample_[4,])), col='darkred',type='l', lwd=2, add = T)
legend("topright", legend = c("Empirical Distribution", TeX("$N(\\bar{X}_1, S_n^2(X_1))$")), col = c("orange", "darkred"),lty = 1, cex = 0.8)
```


```{r}
ks.test(x = sample_[4,], y = "pnorm", mean = mean(sample_[4,]), sd = sd(sample_[4,]))
```

As we can see, we're pretty sure that the component of $\mathbf{X}$ are normally distribuited but we need more statistical significance.
To get another confirm of this, we can look at a [QQ plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot) which is a graphical method for comparing two probability distributions by plotting their quantiles against each other.

We're going to compare the standardized sample distribution against a standard Normal.

```{r echo=FALSE}
z <- (sample_[4,]-mean(sample_[4,]))/sd(sample_[4,]) # We have to standardize our sample to compare it with a standard normal
ggplot() +
    geom_qq(aes(sample = z),colour='orange') +
    geom_abline(intercept = (mean(sample_[4,])/sd(sample_[4,])), slope = 1,
                color = "darkred", size = 1, alpha = 0.5) +
    ggtitle("Normal qq-plot")+theme(plot.title = element_text(hjust = 0.5))
```

The quantiles are very close, but there are more xtreme values than would be expected if they truly came from a Normal distribution. We can try to fit a t-student model to see if we can reconduct this heavier tails to that.

```{r message=FALSE, warning=FALSE}
# Just fitting a t distro
t_fit=fitdistr(X1, 't')
t_fit
```
```{r}
tdf=t_fit$estimate[[3]] # Estimated degrees of freedom
```

```{r echo=FALSE}
dat=data.frame(y=rt(200000, df=tdf))
ggplot(dat, aes(sample = X1)) +
  stat_qq(distribution = qt, dparams = tdf, colour='orange') +
  stat_qq_line(distribution = qt, dparams = tdf, colour='darkred', lwd=1)+
  ggtitle("T-student qq-plot")+theme(plot.title = element_text(hjust = 0.5))
```

The distribution fitting returned a very high number of deegres of freedom and this allows us to approximate the distribution with a normal. Formally (due to the heavy tails) , the components of $\mathbf{X}$ follow a high df t-student distribution and this is interesting becouse it's the same results of the aforementioned hierarchical model.



##Exercise III: Deep-Sky-Bayes

For some strange turn in the history of science, (many) astrophysicists are real Bayesian "evangelists" that use, misuse and
push the old Reverend into their data analytic games as soon as they possibly can. This little_tiny_exercise inspired by a not
so old paper, is just one example of what can be done.
We all know what a star is, and we all know that they form and evolve in decently well-understood way. The Hertzsprung-
Russell diagram where we graph each star in terms of its brightness against its temperature (color), was one of the tools that
led astronomers to speculate about stellar evolution: stars, while fusing hydrogen in their cores, collapse from red giants to
dwarf, and then, in the course of their lifetimes, move down along the so called main sequence, a prominent diagonal band
that runs from the upper left to the lower right of the H-R diagram.
Now, the problem we are tackling here is an old one, strictly related to these issues: determining the stellar initial mass function
(IMF). The IMF plays an extremely crucial role in shaping stellar population: it determines the probability distribution of the
mass at which a star enters the main sequence; it regulates the relative abundance of massive versus low-mass stars for each
stellar generation; it influences most observable properties of stellar population and galaxies, and it is also required as input in
some models of galaxy evolution.
For an astrophysicist the ultimate goal would clearly be to infer the IMF from first principles, but here we content ourselves
with an empirical, data driven alternative: fit the IMF using a lognormal distribution as suggested by Zaninetti but in a
Bayesian framework using OpenBUGS/JAGS.

### The Data

The data available are from 208 stars located in the massive cluster NGC 6611 for which mass measurements are available. Let's load them.

```{r message=FALSE, warning=FALSE}

# reads the data
NGC6611 <- read_csv("D:\\Claudio\\Uni\\NGC6611.csv")
star.data <- NGC6611$Mass
```

We can model the stellar mass using a lognormal model with location and scale parameters $\mu$ and $\sigma^2$.

A pretty good introduction about it can be found [here](https://en.wikipedia.org/wiki/Log-normal_distribution).
Briefly, a log-normal (or lognormal) distribution is a continuous probability distribution of a random variable whose logarithm is normally distributed. Thus, if the random variable $X$ is log-normally distributed, then $Y = \ln(X)$ has a normal distribution. Likewise, if $Y$ has a normal distribution, then the exponential function of $Y$, $X = \exp(Y)$, has a log-normal distribution. A random variable which is log-normally distributed takes only positive real values.
The distribution is summarized by:

- Density: 

$${\displaystyle {\frac {1}{x\sigma {\sqrt {2\pi }}}}\ e^{-{\frac {\left(\ln x-\mu \right)^{2}}{2\sigma ^{2}}}}}$$

- Mean:

$$\exp \left(\mu +{\frac {\sigma ^{2}}{2}}\right)$$

-  Variance: 

$$[\exp(\sigma ^{2})-1]\exp(2\mu +\sigma ^{2})$$

- Median:

$${\displaystyle \exp(\mu )}$$

To get an idea of the physical dimension we're talking about, it's important to know that star unit of mass is the **Solar Mass** which is equal to approximately $2 \cdot 10^{30}$ kg.

### Exploratory Analysis

Before going deeper in Bayesian Inference it's useful to explore the dataset with some standard plots and summary statistics.

Let's check the basic summaries:
```{r}
summaries <- data.frame(Summaries = unclass(summary(star.data)))
kable(summaries)
```


We can see that the actual sample stars have, on average, about the $40 \%$ of the solar mass. But which is their variability?

```{r echo=FALSE}

star.variance <- var(star.data)
star.sd <- sd(star.data)
star.var <- data.frame(Summaries = c(Variance = star.variance, "Standard Deviation" = star.sd))
kable(star.var)
```

The standard deviation is pretty high. On average the star masses are the $(40 \pm 32)\%$ of the solar mass.


We can take a look at the distribution of our data:

```{r echo=FALSE}
hist(star.data, prob = T, col = "orange", border = "white", breaks = 60, xlab = "Star Masses", main = "Star Masses Distribution")
```



A good idea is making a "bite" of frequentist parametric inference on it by computing the MLE for the model parameters $\mu$ and $\sigma^2$.

It can be shown that:

$$\hat\mu_{ML} = \frac{\sum_{i = 1}^n\ln(X_i)}{n}$$
$$ \hat\sigma^2_{ML} = \frac{\sum_{i = 1}^n(\ln(X_i) - \hat\mu)^2}{n}$$


```{r echo=FALSE}

mu_hat <- sum(log(star.data))/length(star.data)
sigma2_hat <- sum((log(star.data)-mu_hat)^2)/length(star.data)
MLE <- data.frame("MLE Estimates" = c("Mi Estimate" = mu_hat,  "Sigma Squared Estimate" = sigma2_hat ) )
kable(MLE)
```

Let's take a look to fitting by overlapping the empirical and the fitted distribution  :

```{r echo=FALSE}
hist(star.data, prob = T, col = "orange", border = "white", breaks = 60, xlab = "Star Masses", main = "Star Masses Distribution")
curve(dlnorm(x  ,meanlog = mu_hat,sdlog = sqrt(sigma2_hat)), col='darkred',type='l', lwd=3, add = T)
legend("topright", legend = c("Empirical Distribution", "Fitted Distribution"), col = c("orange", "darkred"),lty = 1, cex = 0.8)
```

The fitting is pretty good.
Moreover, we're interested in analyzing the skeweness and the "tailedness" of the empirical distro (using Kurtosis measure). Just for completeness, remember that:

- **Skewness** is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive or negative, or undefined.

For a unimodal distribution, negative skew commonly indicates that the tail is on the left side of the distribution, and positive skew indicates that the tail is on the right.

It is defined as:
$$ {\displaystyle \gamma _{1}=\operatorname {E} \left[\left({\frac {X-\mu }{\sigma }}\right)^{3}\right]}$$

- **Kurtosis** is a measure of the "tailedness" of the probability distribution of a real-valued random variable. 

The kurtosis of any univariate normal distribution is 3. It is common to compare the kurtosis of a distribution to this value. Distributions with kurtosis less than 3 are said to be **platykurtic**, although this does not imply the distribution is "flat-topped" as sometimes reported. Rather, it means the distribution produces fewer and less extreme outliers than does the normal distribution.Distributions with kurtosis greater than 3 are said to be **leptokurtic**.

It is defined as:

$$  {\textstyle \operatorname {Kurt} =\operatorname {E} \left[\left({\frac {X-\mu }{\sigma }}\right)^{4}\right]} $$




We obtained:

```{r echo=FALSE}
# Two built-in functions from RFast lib
kurtosis<- kurt(star.data)-3
skewness<-skew(star.data)
ks <- data.frame(Summaries = c(Skewness = skewness, "Kurtosis - 3" = kurtosis))
kable(ks)
```

As we can see and as we can expect the positive value of the skewness indicates that there is a very long right tale while the negative value of the Kurtois - 3 indicates that the distro has tails approaching zero faster than a Gaussian.

In the end, let's take a look at the [boxplot](https://en.wikipedia.org/wiki/Box_plot) of the empirical distribution:

```{r echo=FALSE}
boxplot(star.data, horizontal = T, col='orange', border = 'darkred', xlab = "Star Masses", main = "Star Masses Boxplot")
```

Not too much to say, obviously the informations encoded by this plot are consistent with the previous summaries.


### Inference on $\mu$ and $\sigma^2$ via Bayesian Network 

We wanna build the Bayesian Network associated to the star masses model in order to make inference on $\mu$ and $\sigma^2$. It can be easily structured via [OpenBUGS](http://www.openbugs.net/) using this simple Doodle:

<img src="https://i.imgur.com/3LBpWQy.jpg"/>

Where:

- "mi" is a stochastic node. It represents our prior belief about $\mu$ and we used a ***non-informative*** Gaussian $N(\mu_0, \sigma_0^2=\frac{1}{\tau_0})$ distribution by setting its hyperparameters as follow:

  -- "Mi0" is a constant node. It represents our choice for $\mu_0$ and it's setted to $0$.
  
  -- "Precision0" is a constant node. It represents our choice for $\tau_0$ and it's setted to $0.001$ (high variance).
  
- "sigma" is a stochastic node. It represents our prior belief about $\sigma$ and we used a ***non-informative*** Gamma $G(\alpha, \beta)$ distribution by setting its hyperparameters as follow:

  -- "alpha" is a constant node. It represents our choice for $\alpha$ and it's setted to $0.001$.
  
  -- "beta" is a constant node. It represents our choice for $\beta$ and it's setted to $0.001$.

- "precision" is a logic node. It actuates the transformation $\tau = h(\sigma)=\frac{1}{\sigma^2}$ due to the parametrization choosen by BUGS.
  
_ "Y[i]" is a stochastic plate of dimension $N = \text{number of observed masses}$. It represents our sample, so each observation is a random variable distribuited as $LogN(\mu, \sigma^2 = 1/\tau)$

We're interested in finding the posterior:

$$ \pi(\mu,\sigma^2|\mathbf{Y}_n) = \frac{L(\mathbf{Y}_n)\cdot\pi(\mu,\sigma^2)}{m(\mathbf{Y}_n)} = \frac{p(\mathbf{Y}_n|\mu,\sigma^2)\cdot\pi(\mu,\sigma^2)}{m(\mathbf{Y}_n)}$$
  
This is not trivial (what a surprise!Otherwhise why should we need BUGS?!) but we know we can count on a powerful tool based on the concept of **Markov Chain**: **The Gibbs sampler** (BUGS a.k.a. "Bayesian inference Using Gibbs Sampling"). The theory behind this framework is wide but we briefly wanna remind some basic concepts at the end of this paragraph.

The first step is loading the data and, setting the constants and the initial points of the chains, in this case 3.

<img src = "https://i.imgur.com/CsU99vj.jpg"/>

Now that we've loaded the data, it's time to run the chains. This are the trace plots:

<img src="https://i.imgur.com/SSqxQaA.jpg"/>

<img src="https://i.imgur.com/2IsHejz.jpg"/>

As we can see, the results seem to be acceptable, the history of the chains is what we should see, fluctuations and apparantely no correlation among samples. Anyway, let's take a deeper look at the [autocorrelation](http://ce.sharif.ac.ir/courses/84-85/1/ce695/resources/root/R.P%20Concepts/m10676.pdf) of the process:

<img src="https://i.imgur.com/goMCv0m.jpg" \>

<img src="https://i.imgur.com/CpU9sk8.jpg" \>


From this graph we can apprecciate the goodness of the chain and set a small ***burn-in*** to improve it:

<img src="https://i.imgur.com/2Uq1crS.jpg"/>

Before looking at the estimates for $\mu$ and $\sigma^2$ _via_ the summaries of the obtained posteriors, let's check their shapes:

<img src="https://i.imgur.com/75tR2TB.jpg" \>

<img src="https://i.imgur.com/ZZLGrgL.jpg" \>

The distribution are very bell-shaped. As in the first exercise, some tests can be used to check their normality, but we're not focusing on this now.

We are interested in the aforementioned estimates and we know that:

- The mean of the posterior is the best estimator in the MSE sense due to the fact that:

$$ \operatorname{E}[\boldsymbol{\mu},\sigma|\mathbf{Y}_n]= \arg\min_{d} [\operatorname{MSE(\boldsymbol{\mu},\sigma,d(\mathbf{Y}_n))]} $$

- The median of the posterior is the best estimator in the Absolute Loss ($L_1$) sense due to the fact that:

$$ \operatorname{Median}[\boldsymbol{\mu},\sigma|\mathbf{Y}_n]= \arg\min_{d} [\operatorname{L_1(\boldsymbol{\mu},\sigma,d(\mathbf{Y}_n))]} $$
The obtained estimates of this quantities are:

<img src="https://i.imgur.com/80BRtfP.jpg"\>

From this statistic we also get a good estimate of the **optimal** $95\%$ [credible intervals](https://www.statisticshowto.datasciencecentral.com/credible-interval/) for $\boldsymbol{\mu}$ and $\sigma^2$ by looking at the indicated percentiles, thanks to the unimodal and symmetric shapes of the distribution.
In general, remember that a credible interval at level $1-\alpha$ for an unknown random parameter $\theta$ is defined as:

$$ \int_C \pi(\theta|\mathbf{X}) d\theta = 1-\alpha$$

Where $\pi$ is the posterior probability distribution of the parameter given the data $\mathbf{X}$.

Observe that the obtained estimates are **very** close to the ML values derived from our brief upper frequentist inference and this can be a good indicator of their goodness. 



We can visually compare the two resultant distributions of the stellar masses, but first let's implement the same model using [JAGS](http://mcmc-jags.sourceforge.net/) and its powerful R interface [rjags](https://cran.r-project.org/web/packages/rjags/rjags.pdf).

```{r message=FALSE, warning=FALSE}


# The following functions implements the previous BUGS model in JAGS:
# - mu,prec,a,b are the hyperparameters
# - rand_mu_init, rand_sigma_init are boolean variables that set the chai randomly initialize
# - sim_mu, sim_sigma , sim_a, sim_b are boolean variables that set which of the hyperparameter has to vary (sensitive analysis, read later)

jags_inf <- function( mu = 0,prec = .001,a = .001,b = .001, data = star.data, rand_mu_init = F, rand_sigma_init = F, sim_mu = F, sim_sigma = F, sim_a = F, sim_b = F){


# Random initialization, random seed
if(rand_mu_init|rand_sigma_init){
set.seed(as.integer(runif(1,5,100)))
}
else{
  set.seed(1234)
}

  
# The graphical model, very tiny  
model <-function(){  
  mi ~ dnorm(Mi0, Precision0)
  sigma ~ dgamma(alpha,beta)
  precision <- sigma^-2
  for( i in 1 : N ) {
    Y[i] ~ dlnorm(mi, precision)
  }
}


# Data
dd <-list(Y= data,
          N=length(data), Mi0=mu,
          Precision0=prec,
          alpha=a,
          beta=b)


# Inits(random or not) 
if(rand_mu_init){
  mu_i = runif(3,-100,100)
}
else{
  mu_i = c(0,1,100)
}

if(rand_sigma_init){
  sig2_i = runif(3,0,100) 
}
else{
  sig2_i = c(0.1,1,100)
}


inits1 <- list("mi"=mu_i[1], "sigma"=sig2_i[1])
inits2 <-list("mi"=mu_i[2], "sigma"=sig2_i[2])
inits3 <- list("mi"=mu_i[3], "sigma"=sig2_i[3])
init <- list(inits1,inits2 ,inits3)


# The jags engine
fit <- jags(data = dd, 
            model=model,
            inits = init,
            parameters.to.save = c('mi', 'precision'),
            n.burnin = 100,
            n.iter = 10000,
            n.chains = 3, 
            DIC = FALSE)


# Based on what is requested, the function returns the estimates of mu or sigma
if(sim_mu){
  return(fit$BUGSoutput$mean[[1]])
}
if(sim_sigma){
  return(sqrt(1/fit$BUGSoutput$mean[[2]]))
}

return(fit)
}

fit <- jags_inf()


```
The results has been computed, let's take a look:
```{r echo=FALSE}
fit
mu_jags<-fit$BUGSoutput$mean[[1]]
sigma_jags<-sqrt(1/fit$BUGSoutput$mean[[2]])
```

They're absolutely consistent with OpenBugs ones. Now it's time to visualize the results. 


*LET'S GET READY TO RUMBLE!! Good evening and welcome to tonight's boxing match which promises to be a classic in every sense of the word. In the red corner, weighing in at 10 pounds (I believe so) and the undisputed world champion the man known only as BAYESIAN 'f##k your opinion I'm right' INFERENCE... And in the blue corner weighing in at 6 lbs 5 ounces (growing up with number of supporters) ... FREQUENTIST 'the dimensions matter' INFERENCE !!! And tonight's prize? ETERNAL GLORRRYYY!*

Let's plot,overlapped:

- The empirical distribution of the data.

- The $LogN(\hat\mu_{ML},\hat\sigma^2_{ML})$.

- The $LogN(\hat\mu_{BUGS},\hat\sigma^2_{BUGS})$ (mean values).

- The $LogN(\hat\mu_{JAGS},\hat\sigma^2_{JAGS})$ (mean values).

```{r echo=FALSE}
hist(star.data, prob = T, col = "orange", border = "white", breaks = 60, xlab = "Star Masses", main = "Star Masses Distribution")
curve(dlnorm(x  ,meanlog = mu_hat,sdlog = sqrt(sigma2_hat)), col='darkred',type='l', lwd=3, add = T)
curve(dlnorm(x  ,meanlog = mu_jags,sdlog = sigma_jags), col='orchid',type='l', lwd=3, add = T)
curve(dlnorm(x  ,meanlog = -1.255,sdlog = 1.07), col='purple',type='l', lwd=3, add = T)

legend("topright", legend = c("Empirical Distribution", "MLE","JAGS","BUGS"), col = c("orange", "darkred", "orchid", "purple"),lty = 1, cex = 0.8)
```

The distributions are very very close and this is what we expect. In both cases we are letting data speak for themselves, in fact this is an intrinsic property of the ML technique and a derived property for Bayesian Inference thanks to the choosen non-informative priors.

#### Quick sensitivity analysis

In this paragraph we are going to make a brief sensitivity analysis on the obtained results by varying the priors parameters.
The idea is letting vary $\mu_0$,$\sigma_0$, $\alpha$ and $\beta$ and checking how the estimate $\bar\mu$ and $\bar\sigma$ react to changes. 

To do this, we decided to **randomly** initialize the Markov Chains and so we are properly dealing with other two stochastic processes parametrized by $\theta$ with $\theta \in \Theta:=\{ \mu_0,\sigma_0,\alpha,\beta \}$. Choosen a varying parameter, the other ones are fixed on the default, non-informative values:

$$ \bar\mu(\theta|\Theta - \theta),\, \bar\sigma(\theta|\Theta - \theta)$$
In order to summarize it, our wish is estimating:

$$ \operatorname{E}[\bar\mu(\theta|\Theta - \theta)]$$
$$ \operatorname{E}[\bar\sigma(\theta|\Theta - \theta)]$$

That is,again, a function of $\theta$. We know how to estimate it, for each $\theta$ we just need to take the average of the obtained values:


$$ \bar{\bar\mu}(\theta|\Theta - \theta) = \frac{1}{N}\sum_{i=1}^{N}\bar\mu_i(\theta|\Theta - \theta),\,\,\,\,\,\,\,\bar{\bar\sigma}(\theta|\Theta - \theta) = \frac{1}{N}\sum_{i=1}^{N}\bar\sigma_i(\theta|\Theta - \theta)$$
Where $N$ is the number of realizations we'll observe.

The following code will produce 6 vectors:

1. The values of $\bar{\bar\mu}(\mu_0|\sigma^2_0,\alpha,\beta)$
2. The values of $\bar{\bar\sigma}(\mu_0|\sigma^2_0,\alpha,\beta)$
3. The values of $\bar{\bar\mu}(\sigma^2_0|\mu_0,\alpha,\beta)$
4. The values of $\bar{\bar\sigma}(\sigma^2_0|\mu_0,\alpha,\beta)$
5. The values of $\bar{\bar\mu}(\alpha,\beta|\mu_0,\sigma^2_0,)$
6. The values of $\bar{\bar\sigma}(\alpha,\beta|\mu_0,\sigma^2_0)$

```{r message=FALSE, warning=FALSE}

# The following are the range of values to be tested for each hyperparameter
mu_var <- seq(-1,1,1)
sigma_var <- seq(950,1050,100)
ab_var <- matrix(c(runif(2,0.001,10),runif(2,0.001,10)),nrow=2) # For testing two parameters at the same time we 
                                                                # decided to randomly choose the values

# Number of realizations
number_of_realizations <- 5


# Function that interprets the boolean parameter and sets the right kind of simulation calling
jags_sim <- function(x, mu_seq = NULL, sigma_seq = NULL, ab_seq = NULL,mu = F, sigma_sim=F,mu_sim= F){
  if(!is.null(mu_seq)){
    return(sapply(mu_seq,jags_inf,prec = .001,a = .001,b = .001, data = star.data, rand_mu_init = T, rand_sigma_init = T,sim_mu = mu_sim, sim_sigma = sigma_sim))
  }
  
  if(!is.null(sigma_seq)){
    return(sapply(1/sigma_seq,jags_inf,mu = 0,a = .001,b = .001, data = star.data, rand_mu_init = T, rand_sigma_init = T,sim_mu = mu_sim, sim_sigma = sigma_sim))
  }
  
  if(!is.null(ab_seq)){
    return(mapply(jags_inf,a = ab_seq[1,],b = ab_seq[2,],MoreArgs = list(sim_mu = mu_sim,sim_sigma = sigma_sim)))
  }
  
  
}


# Just executing the function letting varying one parameter at time, as explained above.
# For each of them it grabs the results and takes the mean.
invisible(capture.output())
invisible(capture.output(mu_mu0<- sapply(1:number_of_realizations,jags_sim,mu_seq = mu_var, sigma_seq = NULL, ab_seq = NULL,mu_sim = T)))
mu_mu0<- rowMeans(mu_mu0)
invisible(capture.output(sigma_mu0<- sapply(1:number_of_realizations,jags_sim,mu_seq = mu_var, sigma_seq = NULL, ab_seq = NULL,sigma_sim = T)))
sigma_mu0<-rowMeans(sigma_mu0)
 invisible(capture.output(mu_sigma0 <-sapply(1:number_of_realizations,jags_sim,mu_seq = NULL, sigma_seq = sigma_var, ab_seq = NULL,mu_sim = T)))
mu_sigma0<-rowMeans(mu_sigma0)
invisible(capture.output(sigma_sigma0 <- sapply(1:number_of_realizations,jags_sim,mu_seq = NULL, sigma_seq = sigma_var, ab_seq = NULL,sigma_sim = T)))
sigma_sigma0<-rowMeans(sigma_sigma0)
invisible(capture.output(mu_ab<- sapply(1:number_of_realizations,jags_sim,mu_seq = NULL, sigma_seq = NULL, ab_seq = ab_var,mu_sim = T)))
mu_ab<-rowMeans(mu_ab)
invisible(capture.output(sigma_ab<- sapply(1:number_of_realizations,jags_sim,mu_seq = NULL, sigma_seq = NULL, ab_seq = ab_var,sigma_sim = T)))
sigma_ab<-rowMeans(sigma_ab)

```

Now that we have the results, we can plot them.

- $\mu(\mu_0|\sigma^2_0,\alpha,\beta)$

```{r echo=FALSE}
plot(x = mu_var, y = mu_mu0, type = "l", col = "orange", lwd = 3,xlab = TeX("$\\mu_0$"), ylab = TeX("$\\mu$"))
```


- $\sigma(\mu_0|\sigma^2_0,\alpha,\beta)$

```{r echo=FALSE}
plot(x = mu_var, y = sigma_mu0, type = "l", col = "orange", lwd = 3,xlab = TeX("$\\mu_0$"), ylab = TeX("$\\sigma$") )
```


- $\mu(\sigma^2_0|\mu_0,\alpha,\beta)$

```{r echo=FALSE}
plot(x = sigma_var, y = mu_sigma0, type = "l", col = "orange", lwd = 3, xlab = TeX("$\\sigma^2_0$"), ylab = TeX("$\\mu$") )
```



- $\sigma(\sigma^2_0|\mu_0,\alpha,\beta)$

```{r echo=FALSE}
plot(x = sigma_var, y = sigma_sigma0, type = "l", col = "orange", lwd = 3,xlab = TeX("$\\sigma^2_0$"), ylab = TeX("$\\sigma$") )
```

- $\mu(\alpha,\beta|\mu_0,\sigma^2_0,)$

We summarize the results to avoid a weird 3D visualization:

```{r echo=FALSE}
summariesb <- data.frame(Summaries = c(Mean = mean(mu_ab),"Standard Deviation" = sd(mu_ab)))
kable(summariesb)
```



- $\sigma(\alpha,\beta|\mu_0,\sigma^2_0)$

As above:

```{r echo=FALSE}
summariesb <- data.frame(Summaries = c(Mean = mean(sigma_ab),"Standard Deviation" = sd(sigma_ab)))
kable(summariesb)
```


As we can see, sligthly changes in hyperparameters slightly affects $\mu$ and $\sigma$ and this is what we can expect, becouse we are forcing more the procedure to mediate between our opinion and data evidence, but still in a non-informative fashion.
Theoretically speaking, we can state with a "good" approximation that the analyzed processes are stationary in the observed intervals.


#### Markov Chain and Gibbs Sampling

Formally (but not too much), a sequence of r.v. $\{ \theta(1),...,\theta(t),...,\theta_(n)\}$ forms a Markov chain if,for all $t$, the distribution of the $(t + 1)^{th}$ variable looks like:
$$\theta(t+1)\stackrel{}{\sim}p_{trans}(\theta|\theta(t))$$
 
Roughly, the future state depends on the present but not the past.
As $t\rightarrow \infty$, under general conditions -irreducibility+aperiodicity- the marginal distributions of ${\theta(t)}$ converge to a unique, stationary distribution.
In simple terms, this means that although each variable in the chain depends directly on its predecessor, eventually (as t increases) we reach a point such that for practical purposes, all subsequent values are distributed marginally according to the same fixed distribution, which, crucially, is independent of the starting value $\theta(0)$.
In other words, the chain eventually forgets where it started and conforms to an underlying "equilibrium" distribution.

So how does this help us to generate realizations of $\theta$ from the joint posterior distribution in a Bayesian analysis?

The answer is to choose a **transition distribution** suitable for generating - from an arbitrary initial state $\theta(0)$ - a sequence of realizations whose unique stationary distribution is **the joint posterior** of interest.

Many methods exist for designing and sampling from such transition
distributions, and their suitability depends on the nature of the joint
posterior distribution to be explored.

The **Gibbs sampler** is one of the most widely used mcmc algorithms.

It generates a Markov chain by splitting the vector of random variables $\boldsymbol{\theta}$ into sub-vectors (often scalars) and sampling each sub-vector in turn,
conditional on the most recent values of all other elements of $\theta$.

## How Markov Chain lets you find your favourite video of the Royal Wedding: PageRank

Let's define the countable set $S$ of the possible values of $\theta(t)$ as the **state space** of the chain. If it is finite, it's called *finite state space*.

If the state space of a chain is finite, the transition probability distribution can be represented by a matrix, called the transition matrix, with the $(i, j)^{th}$ element of $\mathbf{P}$ equal to:

$$p_{i,j} = \mathbb{P}(\theta(t+1) = \theta_j|\theta(t)= \theta_i)$$

Since each row of P sums to one and all elements are non-negative, P is a right stochastic matrix.

A stationary distribution $\boldsymbol{\pi}$ is a (row) vector, whose entries are non-negative and sum to 1, is unchanged by the operation of transition matrix $\mathbf{P}$ on it and so is defined by:

$$\boldsymbol{\pi}\mathbf{P}=\boldsymbol{\pi}$$

By comparing this definition with that of an eigenvector we see that the two concepts are related and that

$$\boldsymbol{\pi} = \frac{\mathbf{e}}{\sum_ie_i}$$

is a normalized multiple of a left eigenvector e of the transition matrix PT with an eigenvalue of 1. 

Suppose you have a directed graph that describes the web (a node is a page,an in-edge is a hyperlink to that points to that page, an out-edge is an hyperlink that starts from that page) and suppose you need to give a score to each page.

Google provides search results that match the user's search terms.
Under the hood Google maintains a ranking among websites to make
sure "better" or "more important" websites appear early in the search
results. Instead of solving the whole problem at once, this ranking is
first established globally (independent of the search terms), and only
later websites matching the search query are sorted according to some
rank. In this section we focus on the ranking part.

The fundamental idea is that pages with more in-edges are more important.

A naive approach is to rank the sites by the number of incoming hyperlinks.

Google's idea is to model a [random surfer](https://en.ryte.com/wiki/Random_Surfer_Model) who follows hyperlinks
in the web graph, i.e., performs a random walk. After sufficiently
many steps, the websites can be ranked by how many times they were
visited. The intuition is that websites are visited more often if they
are linked by many other sites, which should be a good measure of
how important a website is.
Since the walk is directed, the random surfer can get stuck in sinks
(nodes with no outgoing edges). To fix this issue, a random website is
chosen for the next step whenever the random surfer reaches a sink.

Let us denote the random surfer matrix describing this [random walk](https://en.wikipedia.org/wiki/Random_walk) by $\mathbf{P}$.

There is no guarantee that this process converges to a stationary distribution. We know that this can be fixed by making the Markov
chain ergodic.
One way to make a Markov chain ergodic is to insert an edge between
every two nodes and so updating the matrix in this way:

$$\mathbf{M} = \alpha \mathbf{P}+(1 - \alpha ) \mathbf{R}$$

Where $\alpha \in (0,1)$ and $\mathbf{R}$ is the matrix in which all entries are $\frac{1}{n}$. 

At this point, the stationary distribution related to this transition matrix represents the score of the pages.


# References

- [Bayesian Networks:
Independencies and Inference](http://www.cs.cmu.edu/~awm/15781/slides/bayesinf05a.pdf)

- [Conditional Independence and
Markov Properties
](http://www.stats.ox.ac.uk/~steffen/stflour/sf1c.pdf)

- [D-separation](https://www.andrew.cmu.edu/user/scheines/tutor/d-sep.html)

- [d-separation: How to determine which variables are independent in a Bayes net](http://web.mit.edu/jmn/www/6.034/d-separation.pdf)

- [Bayesian estimation of the parameters of the normal distribution](https://www.statlect.com/fundamentals-of-statistics/normal-distribution-Bayesian-estimation)

- [Markov Chains & PageRank](https://disco.ethz.ch/courses/fs16/ti2/lecture/chapter11.pdf)

- [The Conjugate Prior for the Normal Distribution](https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/lectures/lecture5.pdf)

- [On the Multivariate t Distribution](http://users.isy.liu.se/en/rt/roth/student.pdf)





  


